{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# State Farm Distracted Driver Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "[State Farm Distracted Driver Detection](https://www.kaggle.com/c/state-farm-distracted-driver-detection)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports und Konstanten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import os, shutil\n",
    "import sys\n",
    "\n",
    "from utils import *\n",
    "from vgg16bn import Vgg16BN\n",
    "\n",
    "from IPython.display import FileLink\n",
    "from keras.preprocessing import image\n",
    "\n",
    "#Instantiate plotting tool\n",
    "#In Jupyter notebooks, you will need to run this command before doing any plotting\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd\n",
    "\n",
    "path = os.getcwd()\n",
    "data_path = os.path.join(path, 'data/')\n",
    "sample_path = os.path.join(path, 'data', 'sample/')\n",
    "\n",
    "train_path = os.path.join(data_path, 'train')\n",
    "valid_path = os.path.join(data_path, 'valid')\n",
    "test_path = os.path.join(data_path, 'test')\n",
    "results_path = os.path.join(data_path, 'results')\n",
    "subm_path = os.path.join(data_path, 'submissions')\n",
    "\n",
    "weights_postfix = 'h5'\n",
    "driver_list_path = 'data/driver_imgs_list.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Vorbereitung der Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### CSV-Datei mit Fahrer-Zuordnung analysieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_driver_df(file_path):\n",
    "    names = ['driver','class','img']\n",
    "    return pd.read_csv(file_path, sep=',',names=names, header=0)\n",
    "\n",
    "def get_driver_imgs(df, driver):\n",
    "    sel = df['driver'] == driver\n",
    "    return df.loc[sel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "driver_df = get_driver_df(driver_list_path)\n",
    "print(driver_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "p002 = get_driver_imgs(driver_df, 'p002')\n",
    "print(p002.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "drivers = driver_df['driver']\n",
    "drivers = drivers.drop_duplicates()\n",
    "print(drivers.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "result = driver_df.groupby('driver') \\\n",
    "             .agg({'class': pd.Series.nunique, 'img':'count'}).reset_index()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "num_total = result['img'].sum()\n",
    "num_move = num_total * 0.2\n",
    "print(num_total)\n",
    "print(num_move)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Verzeichnisse erstellen und Daten bereitstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def create_class_dir(parent_path):\n",
    "    for i in range(10):\n",
    "        class_name = 'c' + str(i)\n",
    "        class_path = os.path.join(parent_path, class_name)\n",
    "        if not os.path.exists(class_path):\n",
    "            os.mkdir(class_path)\n",
    "\n",
    "def create_test_dir(parent_path):\n",
    "    test_path = os.path.join(parent_path, 'test')\n",
    "    if not os.path.exists(test_path):\n",
    "        os.mkdir(test_path)\n",
    "    unknown_path = os.path.join(test_path, 'unknown')\n",
    "    if not os.path.exists(unknown_path):\n",
    "        os.mkdir(unknown_path)\n",
    "\n",
    "def make_dir(parent_path, directory):\n",
    "    path = os.path.join(parent_path, directory)\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)    \n",
    "    \n",
    "def create_train_dir(parent_path):\n",
    "    train_path = os.path.join(parent_path, 'train')\n",
    "    if not os.path.exists(train_path):\n",
    "        os.mkdir(train_path)\n",
    "    create_class_dir(train_path) \n",
    "    \n",
    "def create_valid_dir(parent_path):\n",
    "    valid_path = os.path.join(parent_path, 'valid')\n",
    "    if not os.path.exists(valid_path):\n",
    "        os.mkdir(valid_path)\n",
    "    create_class_dir(valid_path)\n",
    "    \n",
    "def create_sample_dir(parent_path):\n",
    "    sample_path = os.path.join(parent_path, 'sample')\n",
    "    if not os.path.exists(sample_path):\n",
    "        os.mkdir(sample_path)\n",
    "    create_train_dir(sample_path)\n",
    "    create_valid_dir(sample_path)\n",
    "    create_test_dir(sample_path)\n",
    "    make_dir(sample_path, 'results')\n",
    "    make_dir(sample_path, 'submissions')\n",
    "    \n",
    "def fill_valid_dir():\n",
    "    drivers = ['p002', 'p024', 'p051', 'p049']\n",
    "    df = get_driver_df(driver_list_path)\n",
    "    for driver in drivers:\n",
    "        driver_list = get_driver_imgs(df, driver)\n",
    "        move_driver_imgs(train_path, valid_path, driver_list)\n",
    "\n",
    "def prepare_test_dir():\n",
    "    test_files = glob(os.path.join(test_path, '*.jpg'))\n",
    "    target_path = os.path.join(test_path, 'unknown')\n",
    "    for f in test_files:\n",
    "        shutil.move(f, target_path)\n",
    "        \n",
    "def prepare_sample_dir():\n",
    "    sample_train = os.path.join(sample_path, 'train')\n",
    "    sample_valid = os.path.join(sample_path, 'valid')\n",
    "    sample_test = os.path.join(sample_path, 'test')\n",
    "\n",
    "    drivers = ['p014', 'p045', 'p042']\n",
    "    df = get_driver_df(driver_list_path)\n",
    "\n",
    "    for driver in drivers:\n",
    "        driver_list = get_driver_imgs(df, driver)\n",
    "        move_driver_imgs(train_path, sample_train, driver_list, copy=True)\n",
    "    \n",
    "    driver_list = get_driver_imgs(df, 'p072')\n",
    "    move_driver_imgs(train_path, sample_valid, driver_list, copy=True)\n",
    "    \n",
    "    test_files = glob(os.path.join(test_path, 'unknown', '*.jpg'))\n",
    "    shuf = np.random.permutation(test_files)\n",
    "    for i in range(200): \n",
    "        shutil.copy(shuf[i], sample_test)\n",
    "\n",
    "def move_driver_imgs(source_path, target_path, driver_list, copy=False):\n",
    "    for entry in driver_list.values:\n",
    "        file = os.path.join(source_path, entry[1], entry[2])\n",
    "        target = os.path.join(target_path, entry[1])\n",
    "        target_file = os.path.join(target, entry[2])\n",
    "        if os.path.exists(file) and not os.path.exists(target_file):\n",
    "            if copy == True:\n",
    "                shutil.copy(file, target)\n",
    "            else:\n",
    "                shutil.move(file, target)\n",
    "                \n",
    "def prepare_data():\n",
    "    make_dir(data_path, 'results')\n",
    "    make_dir(data_path, 'submission')\n",
    "    create_valid_dir(data_path)\n",
    "    create_sample_dir(data_path)\n",
    "    create_test_dir(data_path)\n",
    "    fill_valid_dir()\n",
    "    prepare_test_dir()\n",
    "    prepare_sample_dir()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Reset all training, validation & sample data\n",
    "def prepare_sample_dir2():\n",
    "    sample_train = os.path.join(sample_path, 'train')\n",
    "    sample_valid = os.path.join(sample_path, 'valid')\n",
    "    sample_test = os.path.join(sample_path, 'test', 'unknown')\n",
    "    \n",
    "    # Copy train and validation files\n",
    "    for class_num in range(10):\n",
    "        class_name = 'c' + str(class_num)\n",
    "        train_files = glob(os.path.join(train_path, class_name, '*.jpg'))\n",
    "        valid_files = glob(os.path.join(valid_path, class_name, '*.jpg'))\n",
    "        target_train = os.path.join(sample_train, class_name)\n",
    "        target_valid = os.path.join(sample_valid, class_name)\n",
    "\n",
    "        shuf = np.random.permutation(train_files)\n",
    "        for i in range(200):\n",
    "            shutil.copy(shuf[i], target_train)\n",
    "        \n",
    "        shuf = np.random.permutation(valid_files)\n",
    "        for i in range(50):\n",
    "            shutil.copy(shuf[i], target_valid)\n",
    "    \n",
    "    # Copy a couple test files\n",
    "    test_files = glob(os.path.join(test_path, 'unknown', '*.jpg'))\n",
    "    shuf = np.random.permutation(test_files)\n",
    "    for i in range(200): \n",
    "        shutil.copy(shuf[i], sample_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Restructure sample directory\n",
    "create_sample_dir(data_path)\n",
    "prepare_sample_dir2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Validate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_class_name(class_id):\n",
    "    class_id_name = { \\\n",
    "        'c0' : 'safe driving', \\\n",
    "        'c1': 'texting - right', \\\n",
    "        'c2': 'talking on the phone - right', \\\n",
    "        'c3': 'texting - left', \\\n",
    "        'c4': 'talking on the phone - left', \\\n",
    "        'c5': 'operating the radio', \\\n",
    "        'c6': 'drinking', \\\n",
    "        'c7': 'reaching behind', \\\n",
    "        'c8': 'hair and makeup', \\\n",
    "        'c9': 'talking to passenger'}\n",
    "    class_name = class_id_name[class_id]\n",
    "    return class_name\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(get_class_name('c2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Helper function to plot images by index in the validation set \n",
    "# Plots is a helper function in utils.py\n",
    "#def plots_idx(idx, titles=None):\n",
    "#    plots([image.load_img(valid_path + filenames[i]) for i in idx], titles=titles)\n",
    "    \n",
    "#Number of images to view for each visualization task\n",
    "n_view = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_random_class_files(parent_path, class_id):\n",
    "    print(class_id + ' - ' + get_class_name(class_id) )\n",
    "    path = os.path.join(parent_path, class_id, '*.jpg')\n",
    "    print path\n",
    "    class_files = glob(os.path.join(parent_path, class_id, '*.jpg'))\n",
    "    shuf = np.random.permutation(class_files)\n",
    "    imgs = []\n",
    "    titles = []\n",
    "    for i in range(4):\n",
    "        imgs.append(image.load_img(shuf[i]))\n",
    "        titles.append(os.path.splitext(os.path.basename(shuf[i]))[0])\n",
    "    plots(imgs, titles=titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_random_class_files(valid_path,'c1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_random_class_files(valid_path,'c2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_random_class_files(valid_path,'c3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_random_class_files(valid_path,'c4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_random_class_files(valid_path,'c5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_random_class_files(valid_path,'c6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_random_class_files(valid_path,'c7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_random_class_files(valid_path,'c8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_random_class_files(valid_path,'c9')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_random_class_files(train_path,'c1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_random_class_files(train_path,'c2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_random_class_files(train_path,'c3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_random_class_files(train_path,'c4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_random_class_files(train_path,'c5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_random_class_files(train_path,'c6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_random_class_files(train_path,'c7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_random_class_files(train_path,'c8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_random_class_files(train_path,'c9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Einfaches Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning und Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "batches = get_batches(train_path, batch_size=batch_size)\n",
    "val_batches = get_batches(valid_path, batch_size=batch_size*2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    BatchNormalization(axis=1, input_shape=(3,224,224)),\n",
    "    Flatten(), \n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit_generator(batches, batches.nb_sample, nb_epoch=2, \n",
    "                    validation_data=val_batches, nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG16 (Imagenet-Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = Vgg16()\n",
    "model = vgg.model\n",
    "last_conv_idx = [i for i,l in enumerate(model.layers) if type(l) is Convolution2D][-1]\n",
    "conv_layers = model.layers[:last_conv_idx+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_model = Sequential(conv_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18542 images belonging to 10 classes.\n",
      "Found 3882 images belonging to 10 classes.\n",
      "Found 79726 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "(val_classes, train_classes, val_labels, train_labels,\n",
    "    val_filenames, filenames, test_filenames) = get_classes(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18542 images belonging to 10 classes.\n",
      "Found 3882 images belonging to 10 classes.\n",
      "Found 79726 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "batches = get_batches(train_path, batch_size=batch_size, shuffle=False)\n",
    "val_batches = get_batches(valid_path, batch_size=batch_size*2, shuffle=False)\n",
    "test_batches = get_batches(test_path, batch_size=batch_size*2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_feat = conv_model.predict_generator(batches, batches.nb_sample)\n",
    "conv_val_feat = conv_model.predict_generator(val_batches, val_batches.nb_sample)\n",
    "conv_test_feat = conv_model.predict_generator(test_batches, test_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = get_data(train_path)\n",
    "val_data = get_data(valid_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_val_feat_file = os.path.join(results_path, 'conv_val_feat.dat')\n",
    "conv_feat_file = os.path.join(results_path, 'conv_feat.dat')\n",
    "conv_test_feat_file = os.path.join(results_path, 'conv_test_feat.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data_file = os.path.join(results_path, 'val_data.dat')\n",
    "train_data_file = os.path.join(results_path, 'train_data.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_array(conv_feat_file, conv_feat)\n",
    "save_array(conv_val_feat_file, conv_val_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_array(train_data_file, train_data)\n",
    "save_array(val_data_file, val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_array(conv_test_feat_file, conv_test_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_array(train_data_file)\n",
    "val_data = load_array(val_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_feat = load_array(conv_feat_file)\n",
    "conv_val_feat = load_array(conv_val_feat_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_test_feat = load_array(conv_test_feat_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3882, 512, 14, 14)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_val_feat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batchnorm dense layer on pretrained conv layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Convolutional-Layer des VGG16-Netzwerks wurden separiert und die Ergebnisse wurden vorberechnet und als bcolz-arrays auf der Harddisk gesichert. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bn_layers(p):\n",
    "    return [\n",
    "        MaxPooling2D(input_shape=conv_layers[-1].output_shape[1:]),\n",
    "        Flatten(),\n",
    "        Dropout(p/2),\n",
    "        Dense(1024, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p/2),\n",
    "        Dense(1024, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p),\n",
    "        Dense(10, activation='softmax')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.8\n",
    "bn_model = Sequential(get_bn_layers(p))\n",
    "bn_model.compile(Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18542 samples, validate on 3882 samples\n",
      "Epoch 1/3\n",
      "18542/18542 [==============================] - 12s - loss: 0.7491 - acc: 0.8132 - val_loss: 0.5662 - val_acc: 0.8382\n",
      "Epoch 2/3\n",
      "18542/18542 [==============================] - 12s - loss: 0.0790 - acc: 0.9766 - val_loss: 0.6133 - val_acc: 0.8050\n",
      "Epoch 3/3\n",
      "18542/18542 [==============================] - 12s - loss: 0.0475 - acc: 0.9854 - val_loss: 0.4359 - val_acc: 0.8730\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f07b3231d90>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_model.fit(conv_feat, train_labels, batch_size=batch_size, nb_epoch=3,\n",
    "            validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bcolz-Array-Iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternativ zum Laden der gesamten vorberechneten Werte soll ein Array-Iterator verwendet werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label_file = os.path.join(results_path, 'train_labels.dat')\n",
    "val_label_file = os.path.join(results_path, 'val_labels.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_array(train_label_file, train_labels)\n",
    "save_array(val_label_file, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "18542/18542 [==============================] - 18s - loss: 0.0822 - acc: 0.9773 - val_loss: 0.6175 - val_acc: 0.8295\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f09d79ab6d0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bc_conv_features = bcolz.open(conv_feat_file, mode='r')\n",
    "bc_train_labels = bcolz.open(train_label_file, mode='r')\n",
    "\n",
    "bc_val_features = bcolz.open(conv_val_feat_file, mode='r')\n",
    "bc_val_labels = bcolz.open(val_label_file, mode='r')\n",
    "\n",
    "train_batches = BcolzArrayIterator(bc_conv_features, bc_train_labels, \n",
    "                                   batch_size=bc_conv_features.chunklen * 10, shuffle=True)\n",
    "\n",
    "val_batches = BcolzArrayIterator(bc_val_features, bc_val_labels, \n",
    "                                 batch_size=bc_val_features.chunklen * 10, shuffle=True)\n",
    "\n",
    "bn_model.fit_generator(generator=train_batches, samples_per_epoch=train_batches.N, \n",
    "                       validation_data=val_batches, nb_val_samples=val_batches.N, nb_epoch=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-computed data augmentation + dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18542, 10)\n"
     ]
    }
   ],
   "source": [
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Ergebnisse des VGG Convolution-Models (ohne Dense-Layer) werden vorberechnet. Als Eingabedaten werden die augmentierten Trainigsdaten (5-fache Gr√∂sse) verwendet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18542, 512, 14, 14)\n"
     ]
    }
   ],
   "source": [
    "print(conv_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_t = image.ImageDataGenerator(rotation_range=15, height_shift_range=0.05, \n",
    "                shear_range=0.1, channel_shift_range=20, width_shift_range=0.1)\n",
    "da_batches = get_batches(train_path, gen_t, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_conv_feat_small = conv_model.predict_generator(da_batches, da_batches.nb_sample*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_da_small_feat_file = os.path.join(results_path, 'conv_da_small_feat.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_array(conv_da_small_feat_file, da_conv_feat_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_conv_feat = load_array(conv_da_feat_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_con_feat_small = load_array(conv_da_small_feat_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die vorberechneten Ergebnisse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_conv_feat = np.concatenate([da_con_feat_small, conv_feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_train_labels = np.concatenate([train_labels]*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bn_da_layers(p):\n",
    "    return [\n",
    "        MaxPooling2D(input_shape=conv_layers[-1].output_shape[1:]),\n",
    "        Flatten(),\n",
    "        Dropout(p),\n",
    "        Dense(1024, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p),\n",
    "        Dense(1024, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p),\n",
    "        Dense(10, activation='softmax')       \n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_model = Sequential(get_bn_da_layers(p))\n",
    "bn_model.compile(Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55626 samples, validate on 3882 samples\n",
      "Epoch 1/1\n",
      "55626/55626 [==============================] - 36s - loss: 1.5926 - acc: 0.5697 - val_loss: 0.4270 - val_acc: 0.8612\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9d40951350>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_model.fit(da_conv_feat, da_train_labels, batch_size=batch_size, nb_epoch=1,\n",
    "            validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_model.optimizer.lr=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55626 samples, validate on 3882 samples\n",
      "Epoch 1/1\n",
      "55626/55626 [==============================] - 36s - loss: 0.5744 - acc: 0.8117 - val_loss: 0.4234 - val_acc: 0.8570\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa80e7ae490>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_model.fit(da_conv_feat, da_train_labels, batch_size=batch_size, nb_epoch=1,\n",
    "            validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_model.optimizer.lr=0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55626 samples, validate on 3882 samples\n",
      "Epoch 1/3\n",
      "55626/55626 [==============================] - 36s - loss: 0.4504 - acc: 0.8528 - val_loss: 0.3616 - val_acc: 0.8743\n",
      "Epoch 2/3\n",
      "55626/55626 [==============================] - 36s - loss: 0.4009 - acc: 0.8702 - val_loss: 0.3948 - val_acc: 0.8676\n",
      "Epoch 3/3\n",
      "55626/55626 [==============================] - 36s - loss: 0.3709 - acc: 0.8798 - val_loss: 0.4182 - val_acc: 0.8570\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa80ee6c750>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_model.fit(da_conv_feat, da_train_labels, batch_size=batch_size, nb_epoch=3,\n",
    "            validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_weights_file = os.path.join(results_path, 'da_conv8_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_model.save_weights(latest_weights_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-computed data augmentation + dropout (BcolzArrayIterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_conv_feat_file = os.path.join(results_path, 'conv_da_small_feat.dat')\n",
    "da_conv_labels_file = os.path.join(results_path, 'conv_da_labels.dat')\n",
    "conv_labels_file = train_label_file\n",
    "conv_val_labels_file = val_label_file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_train_labels = np.concatenate([train_labels]*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_array(da_conv_labels_file, da_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainingsdaten\n",
    "conv_features = bcolz.open(conv_feat_file, mode='r')\n",
    "conv_labels = bcolz.open(conv_labels_file, mode='r')\n",
    "\n",
    "# Augmentierte Trainingsdaten\n",
    "da_conv_features = bcolz.open(da_conv_feat_file, mode='r')\n",
    "da_conv_labels = bcolz.open(da_conv_labels_file, mode='r')\n",
    "\n",
    "# Validierungsdaten\n",
    "val_features = bcolz.open(conv_val_feat_file, mode='r')\n",
    "val_labels = bcolz.open(conv_val_labels_file, mode='r')\n",
    "\n",
    "train_batches = BcolzArrayIterator(conv_features, conv_labels, \n",
    "                                   batch_size=conv_features.chunklen * 10, shuffle=True)\n",
    "\n",
    "da_batches = BcolzArrayIterator(da_conv_features, da_conv_labels, \n",
    "                                   batch_size=da_conv_features.chunklen * 10, shuffle=True)\n",
    "\n",
    "val_batches = BcolzArrayIterator(val_features, val_labels, \n",
    "                                 batch_size=val_features.chunklen * 10, shuffle=True)\n",
    "\n",
    "mix_batches = MixIterator((train_batches, da_batches))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "55626/55626 [==============================] - 33s - loss: 0.3679 - acc: 0.8793 - val_loss: 0.3408 - val_acc: 0.8787\n",
      "Epoch 2/2\n",
      "55626/55626 [==============================] - 32s - loss: 0.3535 - acc: 0.8840 - val_loss: 0.3577 - val_acc: 0.8751\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f078d7299d0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_model.fit_generator(generator=mix_batches, samples_per_epoch=da_batches.N+train_batches.N, \n",
    "                       validation_data=val_batches, nb_val_samples=val_batches.N, nb_epoch=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_model.optimizer.lr=0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pseudo labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pseudo = bn_model.predict(conv_val_feat, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_pseudo = np.concatenate([da_train_labels, val_pseudo])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-5bb1d81b309f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcomb_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mda_conv_feat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv_val_feat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "comb_feat = np.concatenate([da_conv_feat, conv_val_feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_model.load_weights(latest_weights_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_model.fit(comb_feat, comb_pseudo, batch_size=batch_size, nb_epoch=1,\n",
    "            validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_model.fit(comb_feat, comb_pseudo, batch_size=batch_size, nb_epoch=4,\n",
    "            validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_model.optimizer.lr=0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_model.fit(comb_feat, comb_pseudo, batch_size=batch_size, nb_epoch=4,\n",
    "            validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_weights_file = os.path.join(results_path, 'bn_ps8.h5')\n",
    "bn_model.save_weights(latest_weights_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_model.load_weights(latest_weights_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_clip(arr, mx): return np.clip(arr, (1-mx)/9, mx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_test_feat = load_array(conv_test_feat_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = bn_model.predict(conv_test_feat, batch_size=batch_size*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm = do_clip(preds,0.93)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm_name = 'submission_da_3.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = sorted(batches.class_indices, key=batches.class_indices.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>c0</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>c4</th>\n",
       "      <th>c5</th>\n",
       "      <th>c6</th>\n",
       "      <th>c7</th>\n",
       "      <th>c8</th>\n",
       "      <th>c9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_81601.jpg</td>\n",
       "      <td>0.033960</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.027016</td>\n",
       "      <td>0.010161</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.919150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_14887.jpg</td>\n",
       "      <td>0.011181</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.010554</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.930000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_62885.jpg</td>\n",
       "      <td>0.048401</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.114139</td>\n",
       "      <td>0.817953</td>\n",
       "      <td>0.008196</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img_45125.jpg</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.059568</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.009552</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.517102</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.388131</td>\n",
       "      <td>0.014077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img_22633.jpg</td>\n",
       "      <td>0.040571</td>\n",
       "      <td>0.036788</td>\n",
       "      <td>0.013607</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.009744</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.125493</td>\n",
       "      <td>0.766594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             img        c0        c1        c2        c3        c4        c5  \\\n",
       "0  img_81601.jpg  0.033960  0.007778  0.007778  0.007778  0.007778  0.007778   \n",
       "1  img_14887.jpg  0.011181  0.007778  0.007778  0.007778  0.007778  0.010554   \n",
       "2  img_62885.jpg  0.048401  0.007778  0.007778  0.114139  0.817953  0.008196   \n",
       "3  img_45125.jpg  0.007778  0.007778  0.059568  0.007778  0.009552  0.007778   \n",
       "4  img_22633.jpg  0.040571  0.036788  0.013607  0.007778  0.007778  0.009744   \n",
       "\n",
       "         c6        c7        c8        c9  \n",
       "0  0.027016  0.010161  0.007778  0.919150  \n",
       "1  0.007778  0.007778  0.007778  0.930000  \n",
       "2  0.007778  0.007778  0.007778  0.007778  \n",
       "3  0.517102  0.007778  0.388131  0.014077  \n",
       "4  0.007778  0.007778  0.125493  0.766594  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame(subm, columns=classes)\n",
    "submission.insert(0, 'img', [a[8:] for a in test_filenames])\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(subm_name, index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='submission_da_3.gz' target='_blank'>submission_da_3.gz</a><br>"
      ],
      "text/plain": [
       "/home/ubuntu/competitions/distracted-driver/submission_da_3.gz"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FileLink(subm_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### VGG16 Imagenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# --> 0,59\n",
    "#gen = image.ImageDataGenerator(rotation_range=5, width_shift_range=0.05, \n",
    "#                               height_shift_range=0.05, zoom_range=0.05, horizontal_flip=False)\n",
    "\n",
    "#gen = image.ImageDataGenerator(rotation_range=10, width_shift_range=0.1, \n",
    "#                               height_shift_range=0.1, zoom_range=0.1, horizontal_flip=False)\n",
    "\n",
    "gen = image.ImageDataGenerator(rotation_range=15,width_shift_range=0.15, height_shift_range=0.15)\n",
    "\n",
    "#gen = image.ImageDataGenerator()\n",
    "\n",
    "\n",
    "\n",
    "#gen = image.ImageDataGenerator(rotation_range=20, width_shift_range=0.2, \n",
    "#       height_shift_range=0.2, zoom_range=0.2, horizontal_flip=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#import Vgg16 helper class\n",
    "vgg = Vgg16BN()\n",
    "\n",
    "#Set constants. You can experiment with no_of_epochs to improve the model\n",
    "batch_size = 64\n",
    "no_of_epochs = 3\n",
    "\n",
    "#Finetune the model\n",
    "batches = vgg.get_batches(train_path, gen=gen,batch_size=batch_size)\n",
    "val_batches = vgg.get_batches(valid_path, batch_size=batch_size*2)\n",
    "vgg.finetune(batches)\n",
    "\n",
    "layers = vgg.model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Get the index of the first dense layer...\n",
    "first_dense_idx = [index for index,layer in enumerate(layers) if type(layer) is Dense][0]\n",
    "\n",
    "# ...and set this and all subsequent layers to trainable\n",
    "for layer in layers[first_dense_idx:]: \n",
    "    layer.trainable=True\n",
    "    #print(layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "vgg.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "layers = vgg.model.layers\n",
    "for layer in layers:\n",
    "    print(layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "vgg.model.optimizer.lr = 0.0001\n",
    "#print(vgg.model.optimizer.lr.get_value())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Notice we are passing in the validation dataset to the fit() method\n",
    "#For each epoch we test our model against the validation set\n",
    "#latest_weights_filename = None\n",
    "no_of_epochs = 1\n",
    "for epoch in range(no_of_epochs):\n",
    "    print \"Running epoch: %d\" % epoch\n",
    "    vgg.fit(batches, val_batches, nb_epoch=1)\n",
    "    latest_weights_filename = 'ft-bn-final.h5'\n",
    "    weights_path = os.path.join(results_path, latest_weights_filename)\n",
    "    vgg.model.save_weights(weights_path)\n",
    "print \"Completed %s fit operations\" % no_of_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "vgg.fit(batches, val_batches, nb_epoch=1)\n",
    "latest_weights_filename = 'ft-e-1.h5'\n",
    "weights_path = os.path.join(results_path, latest_weights_filename)\n",
    "vgg.model.save_weights(weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "vgg.fit(batches, val_batches, nb_epoch=1)\n",
    "latest_weights_filename = 'ft-e-2.h5'\n",
    "weights_path = os.path.join(results_path, latest_weights_filename)\n",
    "vgg.model.save_weights(weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "vgg.model.optimizer.lr = 0.0001\n",
    "vgg.fit(batches, val_batches, nb_epoch=1)\n",
    "latest_weights_filename = 'ft-e-3.h5'\n",
    "weights_path = os.path.join(results_path, latest_weights_filename)\n",
    "vgg.model.save_weights(weights_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "\n",
    "2-layer (4096, 200) trainable with 4 epochs and learning-rate 0.001 and drop-out = 0.5, 0.3\n",
    "another 4 epochs with lr 0.0001\n",
    "    \n",
    "                        acc     val_acc               acc     val_acc\n",
    "w-0.05,h-0.1,r-5         .8     0.64 \n",
    "w-0.1,h=0.15,r-10       0.69    0.66                  0.79     0.7\n",
    "\n",
    "\n",
    "2-layer (4096, 200) trainable with 4 epochs and learning-rate 0.001 and drop-out = 0.5, 0.5\n",
    "another 4 epochs with lr 0.0001\n",
    "\n",
    "                        acc     val_acc               acc     val_acc\n",
    "w-0.1,h=0.15,r-10       \n",
    "\n",
    "\n",
    "2-layer (200, 200) trainable with 4 epochs and learning-rate 0.001 and drop-out = 0.5, 0.3\n",
    "another 2 epochs with lr 0.0001\n",
    "\n",
    "                        acc     val_acc               acc     val_acc\n",
    "w-0.1,h=0.15,r-10       0.76     0.75                 0.86     0.82\n",
    "\n",
    "with all data          \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "\n",
    "2-layer trainable with 2 epochs and learning-rate 0.001 and drop-out = 0.5\n",
    "\n",
    "                          acc    val_acc\n",
    "standard:                 0.5     0.4\n",
    "width-shift (0.1)         0.4     0.4\n",
    "width-shift (0.2)         0.38    0.36\n",
    "height-shift (0.1)        0.4     0.43\n",
    "height-shift (0.2)        0.37    0.46\n",
    "height-shift (0.3)        0.33    0.37\n",
    "rotation (10)             0.41    0.47\n",
    "rotation (20)             0.37    0.38\n",
    "zoom-range (0.1)          0.41    0.35\n",
    "\n",
    "\n",
    "2-layer trainable with 2 epochs and learning-rate 0.001 and drop-out = 0.3\n",
    "\n",
    "                          acc    val_acc\n",
    "standard:                 0.68     0.48\n",
    "w-0.05,h-0.1,r-0.05       0.48     0.38\n",
    "\n",
    "2-layer trainable with 2 epochs and learning-rate 0.001 and drop-out = 0.6, 0.3\n",
    "\n",
    "                          acc    val_acc        acc   val_acc\n",
    "standard:                 0.55     0.48 \n",
    "w-0.1,h-0.2,r-0.1         0.33     0.42         0.44    0.46     \n",
    "w-0.05,h-0.1,r-0.05       0.42     0.40         0.52    0.45\n",
    "\n",
    "2-layer trainable with 2 epochs and learning-rate 0.001 and drop-out = 0.3, 0.6\n",
    "\n",
    "                          acc    val_acc        acc   val_acc\n",
    "standard:                 0.52     0.43         0.68   0.53\n",
    " \n",
    "2-layer trainable with 2 epochs and learning-rate 0.001 and drop-out = 0.5, 0.2\n",
    "\n",
    "                          acc    val_acc\n",
    "standard:                 0.65     0.48\n",
    "\n",
    "2-layer trainable with 2 epochs and learning-rate 0.01 and drop-out = 0.6, 0.3\n",
    "\n",
    "                          acc    val_acc\n",
    "standard:                 0.63     0.40\n",
    "        \n",
    "\n",
    "2-layer trainable with 2 epochs and learning-rate 0.0001 and drop-out = 0.6, 0.3\n",
    "\n",
    "                          acc    val_acc\n",
    "standard:                 0.16    0.16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "vgg.model.optimizer.lr = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "no_of_epochs = 3\n",
    "for epoch in range(no_of_epochs):\n",
    "    print \"Running epoch: %d\" % epoch\n",
    "    vgg.fit(batches, val_batches, nb_epoch=1)\n",
    "    latest_weights_filename = 'ft-bn-%d.h5' % epoch\n",
    "    weights_path = os.path.join(results_path, latest_weights_filename)\n",
    "    vgg.model.save_weights(weights_path)\n",
    "print \"Completed %s fit operations\" % no_of_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "vgg.model.optimizer.lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Notice we are passing in the validation dataset to the fit() method\n",
    "#For each epoch we test our model against the validation set\n",
    "#latest_weights_filename = None\n",
    "no_of_epochs = 8\n",
    "for epoch in range(no_of_epochs):\n",
    "    print \"Running epoch: %d\" % epoch\n",
    "    vgg.fit(batches, val_batches, nb_epoch=1)\n",
    "    latest_weights_filename = 'ft-bn-%d.h5' % epoch\n",
    "    weights_path = os.path.join(results_path, latest_weights_filename)\n",
    "    vgg.model.save_weights(weights_path)\n",
    "print \"Completed %s fit operations\" % no_of_epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Generate Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's use our new model to make predictions on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def load_weights(weights_file):\n",
    "    vgg.ft(10)\n",
    "    vgg.model.load_weights(weights_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def gen_and_save_preds(weights_file):\n",
    "    weights_path = os.path.join(results_path, weights_file + '.' + weights_postfix)\n",
    "    load_weights(weights_path)\n",
    "    batches, preds = vgg.test(test_path, batch_size = batch_size*2)\n",
    "    preds_path = os.path.join(results_path, 'preds-' + weights_file + '.dat')\n",
    "    files_path = os.path.join(results_path, 'files-' + weights_file + '.dat')\n",
    "    filenames = batches.filenames\n",
    "    save_array(preds_path, preds)\n",
    "    save_array(files_path, filenames)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "weights_file = 'ft-d-2'\n",
    "gen_and_save_preds(weights_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "heading_collapsed": true
   },
   "source": [
    "## Validate Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Keras' *fit()* function conveniently shows us the value of the loss function, and the accuracy, after every epoch (\"*epoch*\" refers to one full run through all training examples). The most important metrics for us to look at are for the validation set, since we want to check for over-fitting. \n",
    "\n",
    "- **Tip**: with our first model we should try to overfit before we start worrying about how to reduce over-fitting - there's no point even thinking about regularization, data augmentation, etc if you're still under-fitting! (We'll be looking at these techniques shortly).\n",
    "\n",
    "As well as looking at the overall metrics, it's also a good idea to look at examples of each of:\n",
    "1. A few correct labels at random\n",
    "2. A few incorrect labels at random\n",
    "3. The most correct labels of each class (ie those with highest probability that are correct)\n",
    "4. The most incorrect labels of each class (ie those with highest probability that are incorrect)\n",
    "5. The most uncertain labels (ie those with probability closest to 0.5)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's see what we can learn from these examples. (In general, this is a particularly useful technique for debugging problems in the model. However, since this model is so simple, there may not be too much to learn at this stage.)\n",
    "\n",
    "Calculate predictions on validation set, so we can find correct and incorrect examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "latest_weights_filename = os.path.join(results_path, 'ft-c-2.h5')\n",
    "vgg.model.load_weights(latest_weights_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "val_batches, probs = vgg.test(valid_path, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "filenames = val_batches.filenames\n",
    "expected_labels = val_batches.classes #0 or 1\n",
    "\n",
    "#Round our predictions to 0/1 to generate labels\n",
    "our_predictions = probs[:,0]\n",
    "our_labels = np.argmax(our_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "our_pred = probs[1200]\n",
    "our_pred = our_pred.clip(0.05, 0.95)\n",
    "label = np.argmax(our_pred)\n",
    "print(our_pred)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "our_preds = probs\n",
    "our_preds = our_preds.clip(0.05, 0.95)\n",
    "our_labels = np.argmax(our_preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(expected_labels[:600])\n",
    "print(our_labels[:600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "#Helper function to plot images by index in the validation set \n",
    "#Plots is a helper function in utils.py\n",
    "def plots_idx(idx, titles=None):\n",
    "    plots([image.load_img(valid_path + filenames[i]) for i in idx], titles=titles)\n",
    "    \n",
    "#Number of images to view for each visualization task\n",
    "n_view = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#1. A few correct labels at random\n",
    "correct = np.where(our_labels==expected_labels)[0]\n",
    "print \"Found %d correct labels\" % len(correct)\n",
    "idx = permutation(correct)[:n_view]\n",
    "print(idx)\n",
    "title_label = our_labels[idx]\n",
    "title_pred = our_preds[idx]\n",
    "print(title_label)\n",
    "print(title_pred)\n",
    "#plots_idx(idx, [our_labels[idx], 'test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(title_pred[3][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#2. A few incorrect labels at random\n",
    "incorrect = np.where(our_labels!=expected_labels)[0]\n",
    "print \"Found %d incorrect labels\" % len(incorrect)\n",
    "idx = permutation(incorrect)[:n_view]\n",
    "plots_idx(idx, our_predictions[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#3a. The images we most confident were cats, and are actually cats\n",
    "correct_cats = np.where((our_labels==0) & (our_labels==expected_labels))[0]\n",
    "print \"Found %d confident correct cats labels\" % len(correct_cats)\n",
    "most_correct_cats = np.argsort(our_predictions[correct_cats])[::-1][:n_view]\n",
    "plots_idx(correct_cats[most_correct_cats], our_predictions[correct_cats][most_correct_cats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#3b. The images we most confident were dogs, and are actually dogs\n",
    "correct_dogs = np.where((our_labels==1) & (our_labels==expected_labels))[0]\n",
    "print \"Found %d confident correct dogs labels\" % len(correct_dogs)\n",
    "most_correct_dogs = np.argsort(our_predictions[correct_dogs])[:n_view]\n",
    "plots_idx(correct_dogs[most_correct_dogs], our_predictions[correct_dogs][most_correct_dogs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#4a. The images we were most confident were cats, but are actually dogs\n",
    "incorrect_cats = np.where((our_labels==0) & (our_labels!=expected_labels))[0]\n",
    "print \"Found %d incorrect cats\" % len(incorrect_cats)\n",
    "if len(incorrect_cats):\n",
    "    most_incorrect_cats = np.argsort(our_predictions[incorrect_cats])[::-1][:n_view]\n",
    "    plots_idx(incorrect_cats[most_incorrect_cats], our_predictions[incorrect_cats][most_incorrect_cats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#4b. The images we were most confident were dogs, but are actually cats\n",
    "incorrect_dogs = np.where((our_labels==1) & (our_labels!=expected_labels))[0]\n",
    "print \"Found %d incorrect dogs\" % len(incorrect_dogs)\n",
    "if len(incorrect_dogs):\n",
    "    most_incorrect_dogs = np.argsort(our_predictions[incorrect_dogs])[:n_view]\n",
    "    plots_idx(incorrect_dogs[most_incorrect_dogs], our_predictions[incorrect_dogs][most_incorrect_dogs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#5. The most uncertain labels (ie those with probability closest to 0.5).\n",
    "most_uncertain = np.argsort(np.abs(our_predictions-0.5))\n",
    "plots_idx(most_uncertain[:n_view], our_predictions[most_uncertain])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Perhaps the most common way to analyze the result of a classification model is to use a [confusion matrix](http://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/). Scikit-learn has a convenient function we can use for this purpose:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(expected_labels, our_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can just print out the confusion matrix, or we can show a graphical view (which is mainly useful for dependents with a larger number of categories)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm, val_batches.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Submit Predictions to Kaggle!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Load our test predictions from file\n",
    "def load_preds(weights_file):\n",
    "    preds_path = os.path.join(results_path, 'preds-' + weights_file + '.dat')\n",
    "    files_path = os.path.join(results_path, 'files-' + weights_file + '.dat')\n",
    "    preds = load_array(preds_path)\n",
    "    files = load_array(files_path)\n",
    "    file_ids = np.array([f[8:] for f in files])\n",
    "    return preds, file_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def prepare_result_df(preds, file_ids):\n",
    "    df1 = pd.DataFrame(data=file_ids, columns=['img'])\n",
    "    df2 = pd.DataFrame(data=preds, columns=['c0', 'c1','c2','c3','c4','c5','c6','c7','c8','c9'])\n",
    "    result = pd.concat([df1, df2], axis=1) \n",
    "    result = result.set_index('img')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def write_submission_df(df, weights_file):\n",
    "    file_path = os.path.join(subm_path, 'subm-' + weights_file + '.csv' )\n",
    "    df.to_csv(file_path, sep=',', float_format='%.3f')\n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def create_submission(weights_file):\n",
    "    preds, file_ids = load_preds(weights_file)\n",
    "    result_df = prepare_result_df(preds, file_ids)\n",
    "    file_path = write_submission_df(result_df, weights_file)\n",
    "    FileLink(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "weights_file = 'ft-bn-1'\n",
    "create_submission(weights_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "nav_menu": {},
  "nbpresent": {
   "slides": {
    "28b43202-5690-4169-9aca-6b9dabfeb3ec": {
     "id": "28b43202-5690-4169-9aca-6b9dabfeb3ec",
     "prev": null,
     "regions": {
      "3bba644a-cf4d-4a49-9fbd-e2554428cf9f": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "f3d3a388-7e2a-4151-9b50-c20498fceacc",
        "part": "whole"
       },
       "id": "3bba644a-cf4d-4a49-9fbd-e2554428cf9f"
      }
     }
    },
    "8104def2-4b68-44a0-8f1b-b03bf3b2a079": {
     "id": "8104def2-4b68-44a0-8f1b-b03bf3b2a079",
     "prev": "28b43202-5690-4169-9aca-6b9dabfeb3ec",
     "regions": {
      "7dded777-1ddf-4100-99ae-25cf1c15b575": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "fe47bd48-3414-4657-92e7-8b8d6cb0df00",
        "part": "whole"
       },
       "id": "7dded777-1ddf-4100-99ae-25cf1c15b575"
      }
     }
    }
   },
   "themes": {}
  },
  "toc": {
   "nav_menu": {
    "height": "148px",
    "width": "254px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
