{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# State Farm Distracted Driver Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "[State Farm Distracted Driver Detection](https://www.kaggle.com/c/state-farm-distracted-driver-detection)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports und Konstanten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import os, shutil\n",
    "import sys\n",
    "\n",
    "from utils import *\n",
    "from vgg16 import Vgg16\n",
    "\n",
    "from IPython.display import FileLink\n",
    "\n",
    "#Instantiate plotting tool\n",
    "#In Jupyter notebooks, you will need to run this command before doing any plotting\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%pwd\n",
    "\n",
    "path = os.getcwd()\n",
    "data_path = os.path.join(path, 'data', 'sample')\n",
    "sample_path = os.path.join(path, 'data', 'sample')\n",
    "\n",
    "train_path = os.path.join(data_path, 'train')\n",
    "valid_path = os.path.join(data_path, 'valid')\n",
    "test_path = os.path.join(data_path, 'test')\n",
    "results_path = os.path.join(data_path, 'results')\n",
    "subm_path = os.path.join(data_path, 'submissions')\n",
    "\n",
    "weights_postfix = 'h5'\n",
    "driver_list_path = 'data/driver_imgs_list.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vorbereitung der Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### CSV-Datei mit Fahrer-Zuordnung analysieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_driver_df(file_path):\n",
    "    names = ['driver','class','img']\n",
    "    return pd.read_csv(file_path, sep=',',names=names, header=0)\n",
    "\n",
    "def get_driver_imgs(df, driver):\n",
    "    sel = df['driver'] == driver\n",
    "    return df.loc[sel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  driver class            img\n",
      "0   p002    c0  img_44733.jpg\n",
      "1   p002    c0  img_72999.jpg\n",
      "2   p002    c0  img_25094.jpg\n",
      "3   p002    c0  img_69092.jpg\n",
      "4   p002    c0  img_92629.jpg\n"
     ]
    }
   ],
   "source": [
    "driver_df = get_driver_df(driver_list_path)\n",
    "print(driver_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  driver class            img\n",
      "0   p002    c0  img_44733.jpg\n",
      "1   p002    c0  img_72999.jpg\n",
      "2   p002    c0  img_25094.jpg\n",
      "3   p002    c0  img_69092.jpg\n",
      "4   p002    c0  img_92629.jpg\n"
     ]
    }
   ],
   "source": [
    "p002 = get_driver_imgs(driver_df, 'p002')\n",
    "print(p002.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['p002' 'p012' 'p014' 'p015' 'p016' 'p021' 'p022' 'p024' 'p026' 'p035' 'p039' 'p041' 'p042' 'p045'\n",
      " 'p047' 'p049' 'p050' 'p051' 'p052' 'p056' 'p061' 'p064' 'p066' 'p072' 'p075' 'p081']\n"
     ]
    }
   ],
   "source": [
    "drivers = driver_df['driver']\n",
    "drivers = drivers.drop_duplicates()\n",
    "print(drivers.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   driver  class   img\n",
      "0    p002     10   725\n",
      "1    p012     10   823\n",
      "2    p014     10   876\n",
      "3    p015     10   875\n",
      "4    p016     10  1078\n",
      "5    p021     10  1237\n",
      "6    p022     10  1233\n",
      "7    p024     10  1226\n",
      "8    p026     10  1196\n",
      "9    p035     10   848\n",
      "10   p039     10   651\n",
      "11   p041     10   605\n",
      "12   p042     10   591\n",
      "13   p045     10   724\n",
      "14   p047     10   835\n",
      "15   p049     10  1011\n",
      "16   p050     10   790\n",
      "17   p051     10   920\n",
      "18   p052     10   740\n",
      "19   p056     10   794\n",
      "20   p061     10   809\n",
      "21   p064     10   820\n",
      "22   p066     10  1034\n",
      "23   p072     10   346\n",
      "24   p075     10   814\n",
      "25   p081     10   823\n"
     ]
    }
   ],
   "source": [
    "result = driver_df.groupby('driver') \\\n",
    "             .agg({'class': pd.Series.nunique, 'img':'count'}).reset_index()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22424\n",
      "4484.8\n"
     ]
    }
   ],
   "source": [
    "num_total = result['img'].sum()\n",
    "num_move = num_total * 0.2\n",
    "print(num_total)\n",
    "print(num_move)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Verzeichnisse erstellen und Daten bereitstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def create_class_dir(parent_path):\n",
    "    for i in range(10):\n",
    "        class_name = 'c' + str(i)\n",
    "        class_path = os.path.join(parent_path, class_name)\n",
    "        if not os.path.exists(class_path):\n",
    "            os.mkdir(class_path)\n",
    "\n",
    "def create_test_dir(parent_path):\n",
    "    test_path = os.path.join(parent_path, 'test')\n",
    "    if not os.path.exists(test_path):\n",
    "        os.mkdir(test_path)\n",
    "    unknown_path = os.path.join(test_path, 'unknown')\n",
    "    if not os.path.exists(unknown_path):\n",
    "        os.mkdir(unknown_path)\n",
    "\n",
    "def make_dir(parent_path, directory):\n",
    "    path = os.path.join(parent_path, directory)\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)    \n",
    "    \n",
    "def create_train_dir(parent_path):\n",
    "    train_path = os.path.join(parent_path, 'train')\n",
    "    if not os.path.exists(train_path):\n",
    "        os.mkdir(train_path)\n",
    "    create_class_dir(train_path) \n",
    "    \n",
    "def create_valid_dir(parent_path):\n",
    "    valid_path = os.path.join(parent_path, 'valid')\n",
    "    if not os.path.exists(valid_path):\n",
    "        os.mkdir(valid_path)\n",
    "    create_class_dir(valid_path)\n",
    "    \n",
    "def create_sample_dir(parent_path):\n",
    "    sample_path = os.path.join(parent_path, 'sample')\n",
    "    if not os.path.exists(sample_path):\n",
    "        os.mkdir(sample_path)\n",
    "    create_train_dir(sample_path)\n",
    "    create_valid_dir(sample_path)\n",
    "    create_test_dir(sample_path)\n",
    "    make_dir(sample_path, 'results')\n",
    "    make_dir(sample_path, 'submissions')\n",
    "    \n",
    "def fill_valid_dir():\n",
    "    drivers = ['p002', 'p024', 'p051', 'p049']\n",
    "    df = get_driver_df(driver_list_path)\n",
    "    for driver in drivers:\n",
    "        driver_list = get_driver_imgs(df, driver)\n",
    "        move_driver_imgs(train_path, valid_path, driver_list)\n",
    "\n",
    "def prepare_test_dir():\n",
    "    test_files = glob(os.path.join(test_path, '*.jpg'))\n",
    "    target_path = os.path.join(test_path, 'unknown')\n",
    "    for f in test_files:\n",
    "        shutil.move(f, target_path)\n",
    "        \n",
    "def prepare_sample_dir():\n",
    "    sample_train = os.path.join(sample_path, 'train')\n",
    "    sample_valid = os.path.join(sample_path, 'valid')\n",
    "    sample_test = os.path.join(sample_path, 'test')\n",
    "\n",
    "    drivers = ['p014', 'p045', 'p042']\n",
    "    df = get_driver_df(driver_list_path)\n",
    "\n",
    "    for driver in drivers:\n",
    "        driver_list = get_driver_imgs(df, driver)\n",
    "        move_driver_imgs(train_path, sample_train, driver_list, copy=True)\n",
    "    \n",
    "    driver_list = get_driver_imgs(df, 'p072')\n",
    "    move_driver_imgs(train_path, sample_valid, driver_list, copy=True)\n",
    "    \n",
    "    test_files = glob(os.path.join(test_path, 'unknown', '*.jpg'))\n",
    "    shuf = np.random.permutation(test_files)\n",
    "    for i in range(200): \n",
    "        shutil.copy(shuf[i], sample_test)\n",
    "\n",
    "def move_driver_imgs(source_path, target_path, driver_list, copy=False):\n",
    "    for entry in driver_list.values:\n",
    "        file = os.path.join(source_path, entry[1], entry[2])\n",
    "        target = os.path.join(target_path, entry[1])\n",
    "        target_file = os.path.join(target, entry[2])\n",
    "        if os.path.exists(file) and not os.path.exists(target_file):\n",
    "            if copy == True:\n",
    "                shutil.copy(file, target)\n",
    "            else:\n",
    "                shutil.move(file, target)\n",
    "                \n",
    "def prepare_data():\n",
    "    make_dir(data_path, 'results')\n",
    "    make_dir(data_path, 'submission')\n",
    "    create_valid_dir(data_path)\n",
    "    create_sample_dir(data_path)\n",
    "    create_test_dir(data_path)\n",
    "    fill_valid_dir()\n",
    "    prepare_test_dir()\n",
    "    prepare_sample_dir()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "prepare_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Finetuning und Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2191 images belonging to 10 classes.\n",
      "Found 346 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "#import Vgg16 helper class\n",
    "vgg = Vgg16()\n",
    "\n",
    "#Set constants. You can experiment with no_of_epochs to improve the model\n",
    "batch_size = 64\n",
    "no_of_epochs = 3\n",
    "\n",
    "#Finetune the model\n",
    "batches = vgg.get_batches(train_path, batch_size=batch_size)\n",
    "val_batches = vgg.get_batches(valid_path, batch_size=batch_size*2)\n",
    "vgg.finetune(batches)\n",
    "\n",
    "#Not sure if we set this for all fits\n",
    "#vgg.model.optimizer.lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running epoch: 0\n",
      "Epoch 1/1\n",
      "2191/2191 [==============================] - 66s - loss: 2.9121 - acc: 0.3108 - val_loss: 3.8031 - val_acc: 0.1098\n",
      "Running epoch: 1\n",
      "Epoch 1/1\n",
      "2191/2191 [==============================] - 66s - loss: 1.0125 - acc: 0.6773 - val_loss: 4.7251 - val_acc: 0.1012\n",
      "Running epoch: 2\n",
      "Epoch 1/1\n",
      "2191/2191 [==============================] - 66s - loss: 0.6137 - acc: 0.7864 - val_loss: 5.4454 - val_acc: 0.0925\n",
      "Completed 3 fit operations\n"
     ]
    }
   ],
   "source": [
    "#Notice we are passing in the validation dataset to the fit() method\n",
    "#For each epoch we test our model against the validation set\n",
    "latest_weights_filename = None\n",
    "for epoch in range(no_of_epochs):\n",
    "    print \"Running epoch: %d\" % epoch\n",
    "    vgg.fit(batches, val_batches, nb_epoch=1)\n",
    "    latest_weights_filename = 'ft%d.h5' % epoch\n",
    "    weights_path = os.path.join(results_path, latest_weights_filename)\n",
    "    vgg.model.save_weights(weights_path)\n",
    "print \"Completed %s fit operations\" % no_of_epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use our new model to make predictions on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_weights(weights_file):\n",
    "    vgg.ft(10)\n",
    "    vgg.model.load_weights(weights_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def gen_and_save_preds(weights_file):\n",
    "    weights_path = os.path.join(results_path, weights_file + '.' + weights_postfix)\n",
    "    load_weights(weights_path)\n",
    "    batches, preds = vgg.test(test_path, batch_size = batch_size*2)\n",
    "    preds_path = os.path.join(results_path, 'preds-' + weights_file + '.dat')\n",
    "    files_path = os.path.join(results_path, 'files-' + weights_file + '.dat')\n",
    "    filenames = batches.filenames\n",
    "    save_array(preds_path, preds)\n",
    "    save_array(files_path, filenames)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "weights_file = 'ft2'\n",
    "gen_and_save_preds(weights_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "heading_collapsed": true
   },
   "source": [
    "## Validate Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Keras' *fit()* function conveniently shows us the value of the loss function, and the accuracy, after every epoch (\"*epoch*\" refers to one full run through all training examples). The most important metrics for us to look at are for the validation set, since we want to check for over-fitting. \n",
    "\n",
    "- **Tip**: with our first model we should try to overfit before we start worrying about how to reduce over-fitting - there's no point even thinking about regularization, data augmentation, etc if you're still under-fitting! (We'll be looking at these techniques shortly).\n",
    "\n",
    "As well as looking at the overall metrics, it's also a good idea to look at examples of each of:\n",
    "1. A few correct labels at random\n",
    "2. A few incorrect labels at random\n",
    "3. The most correct labels of each class (ie those with highest probability that are correct)\n",
    "4. The most incorrect labels of each class (ie those with highest probability that are incorrect)\n",
    "5. The most uncertain labels (ie those with probability closest to 0.5)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's see what we can learn from these examples. (In general, this is a particularly useful technique for debugging problems in the model. However, since this model is so simple, there may not be too much to learn at this stage.)\n",
    "\n",
    "Calculate predictions on validation set, so we can find correct and incorrect examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "vgg.model.load_weights(results_path+latest_weights_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "val_batches, probs = vgg.test(valid_path, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "filenames = val_batches.filenames\n",
    "expected_labels = val_batches.classes #0 or 1\n",
    "\n",
    "#Round our predictions to 0/1 to generate labels\n",
    "our_predictions = probs[:,0]\n",
    "our_labels = np.argmax(our_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.05  0.05  0.05  0.05  0.05  0.05  0.95  0.05  0.05  0.05]\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "our_pred = probs[1200]\n",
    "our_pred = our_pred.clip(0.05, 0.95)\n",
    "label = np.argmax(our_pred)\n",
    "print(our_pred)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "our_preds = probs\n",
    "our_preds = our_preds.clip(0.05, 0.95)\n",
    "our_labels = np.argmax(our_preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(expected_labels[:600])\n",
    "print(our_labels[:600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "#Helper function to plot images by index in the validation set \n",
    "#Plots is a helper function in utils.py\n",
    "def plots_idx(idx, titles=None):\n",
    "    plots([image.load_img(valid_path + filenames[i]) for i in idx], titles=titles)\n",
    "    \n",
    "#Number of images to view for each visualization task\n",
    "n_view = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1740 correct labels\n",
      "[1763  772 1955 1016]\n",
      "[8 3 9 5]\n",
      "[[ 0.05    0.05    0.05    0.05    0.05    0.05    0.1015  0.05    0.7608  0.05  ]\n",
      " [ 0.05    0.05    0.05    0.9239  0.05    0.05    0.05    0.05    0.05    0.05  ]\n",
      " [ 0.0969  0.05    0.05    0.05    0.05    0.05    0.1933  0.05    0.05    0.6416]\n",
      " [ 0.05    0.05    0.05    0.05    0.05    0.95    0.05    0.05    0.05    0.05  ]]\n"
     ]
    }
   ],
   "source": [
    "#1. A few correct labels at random\n",
    "correct = np.where(our_labels==expected_labels)[0]\n",
    "print \"Found %d correct labels\" % len(correct)\n",
    "idx = permutation(correct)[:n_view]\n",
    "print(idx)\n",
    "title_label = our_labels[idx]\n",
    "title_pred = our_preds[idx]\n",
    "print(title_label)\n",
    "print(title_pred)\n",
    "#plots_idx(idx, [our_labels[idx], 'test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95\n"
     ]
    }
   ],
   "source": [
    "print(title_pred[3][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#2. A few incorrect labels at random\n",
    "incorrect = np.where(our_labels!=expected_labels)[0]\n",
    "print \"Found %d incorrect labels\" % len(incorrect)\n",
    "idx = permutation(incorrect)[:n_view]\n",
    "plots_idx(idx, our_predictions[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#3a. The images we most confident were cats, and are actually cats\n",
    "correct_cats = np.where((our_labels==0) & (our_labels==expected_labels))[0]\n",
    "print \"Found %d confident correct cats labels\" % len(correct_cats)\n",
    "most_correct_cats = np.argsort(our_predictions[correct_cats])[::-1][:n_view]\n",
    "plots_idx(correct_cats[most_correct_cats], our_predictions[correct_cats][most_correct_cats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#3b. The images we most confident were dogs, and are actually dogs\n",
    "correct_dogs = np.where((our_labels==1) & (our_labels==expected_labels))[0]\n",
    "print \"Found %d confident correct dogs labels\" % len(correct_dogs)\n",
    "most_correct_dogs = np.argsort(our_predictions[correct_dogs])[:n_view]\n",
    "plots_idx(correct_dogs[most_correct_dogs], our_predictions[correct_dogs][most_correct_dogs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#4a. The images we were most confident were cats, but are actually dogs\n",
    "incorrect_cats = np.where((our_labels==0) & (our_labels!=expected_labels))[0]\n",
    "print \"Found %d incorrect cats\" % len(incorrect_cats)\n",
    "if len(incorrect_cats):\n",
    "    most_incorrect_cats = np.argsort(our_predictions[incorrect_cats])[::-1][:n_view]\n",
    "    plots_idx(incorrect_cats[most_incorrect_cats], our_predictions[incorrect_cats][most_incorrect_cats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#4b. The images we were most confident were dogs, but are actually cats\n",
    "incorrect_dogs = np.where((our_labels==1) & (our_labels!=expected_labels))[0]\n",
    "print \"Found %d incorrect dogs\" % len(incorrect_dogs)\n",
    "if len(incorrect_dogs):\n",
    "    most_incorrect_dogs = np.argsort(our_predictions[incorrect_dogs])[:n_view]\n",
    "    plots_idx(incorrect_dogs[most_incorrect_dogs], our_predictions[incorrect_dogs][most_incorrect_dogs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#5. The most uncertain labels (ie those with probability closest to 0.5).\n",
    "most_uncertain = np.argsort(np.abs(our_predictions-0.5))\n",
    "plots_idx(most_uncertain[:n_view], our_predictions[most_uncertain])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Perhaps the most common way to analyze the result of a classification model is to use a [confusion matrix](http://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/). Scikit-learn has a convenient function we can use for this purpose:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(expected_labels, our_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can just print out the confusion matrix, or we can show a graphical view (which is mainly useful for dependents with a larger number of categories)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm, val_batches.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit Predictions to Kaggle!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load our test predictions from file\n",
    "def load_preds(weights_file):\n",
    "    preds_path = os.path.join(results_path, 'preds-' + weights_file + '.dat')\n",
    "    files_path = os.path.join(results_path, 'files-' + weights_file + '.dat')\n",
    "    preds = load_array(preds_path)\n",
    "    files = load_array(files_path)\n",
    "    file_ids = np.array([f[8:] for f in files])\n",
    "    return preds, file_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_result_df(preds, file_ids):\n",
    "    df1 = pd.DataFrame(data=file_ids, columns=['img'])\n",
    "    df2 = pd.DataFrame(data=preds, columns=['c0', 'c1','c2','c3','c4','c5','c6','c7','c8','c9'])\n",
    "    result = pd.concat([df1, df2], axis=1) \n",
    "    result = result.set_index('img')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_submission_df(df, weights_file):\n",
    "    file_path = os.path.join(subm_path, 'subm-' + weights_file + '.csv' )\n",
    "    df.to_csv(file_path, sep=',', float_format='%.3f')\n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_submission(weights_file):\n",
    "    preds, file_ids = load_preds(weights_file)\n",
    "    result_df = prepare_result_df(preds, file_ids)\n",
    "    file_path = write_submission_df(result_df, weights_file)\n",
    "    FileLink(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights_file = 'ft2'\n",
    "create_submission(weights_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "nav_menu": {},
  "nbpresent": {
   "slides": {
    "28b43202-5690-4169-9aca-6b9dabfeb3ec": {
     "id": "28b43202-5690-4169-9aca-6b9dabfeb3ec",
     "prev": null,
     "regions": {
      "3bba644a-cf4d-4a49-9fbd-e2554428cf9f": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "f3d3a388-7e2a-4151-9b50-c20498fceacc",
        "part": "whole"
       },
       "id": "3bba644a-cf4d-4a49-9fbd-e2554428cf9f"
      }
     }
    },
    "8104def2-4b68-44a0-8f1b-b03bf3b2a079": {
     "id": "8104def2-4b68-44a0-8f1b-b03bf3b2a079",
     "prev": "28b43202-5690-4169-9aca-6b9dabfeb3ec",
     "regions": {
      "7dded777-1ddf-4100-99ae-25cf1c15b575": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "fe47bd48-3414-4657-92e7-8b8d6cb0df00",
        "part": "whole"
       },
       "id": "7dded777-1ddf-4100-99ae-25cf1c15b575"
      }
     }
    }
   },
   "themes": {}
  },
  "toc": {
   "nav_menu": {
    "height": "148px",
    "width": "254px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
